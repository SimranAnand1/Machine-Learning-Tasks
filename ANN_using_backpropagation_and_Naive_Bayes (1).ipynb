{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "ANN using backpropagation and Naive Bayes.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K3clcxRU2x6"
      },
      "source": [
        "\n",
        "## Name: Simran Anand\n",
        "\n"
      ],
      "id": "1K3clcxRU2x6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f4a4c0a"
      },
      "source": [
        "### 1.\tAssuming a set of documents that need to be classified, use the na√Øve Bayesian Classifier model to perform this task. "
      ],
      "id": "7f4a4c0a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95a2c985",
        "outputId": "900230d2-ae1f-4301-d007-a1259e863e64"
      },
      "source": [
        "import pandas as pd\n",
        "msg=pd.read_csv('C:/Users/simran/Downloads/naivetext.csv',names=['message','label'])\n",
        "print('The dimensions of the dataset',msg.shape)\n",
        "msg['labelnum']=msg.label.map({'pos':1,'neg':0})\n",
        "X=msg.message\n",
        "y=msg.labelnum\n",
        "print(X)\n",
        "print(y)"
      ],
      "id": "95a2c985",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dimensions of the dataset (18, 2)\n",
            "0                      I love this sandwich\n",
            "1                  This is an amazing place\n",
            "2        I feel very good about these beers\n",
            "3                      This is my best work\n",
            "4                      What an awesome view\n",
            "5             I do not like this restaurant\n",
            "6                  I am tired of this stuff\n",
            "7                    I can't deal with this\n",
            "8                      He is my sworn enemy\n",
            "9                       My boss is horrible\n",
            "10                 This is an awesome place\n",
            "11    I do not like the taste of this juice\n",
            "12                          I love to dance\n",
            "13        I am sick and tired of this place\n",
            "14                     What a great holiday\n",
            "15           That is a bad locality to stay\n",
            "16           We will have good fun tomorrow\n",
            "17         I went to my enemy's house today\n",
            "Name: message, dtype: object\n",
            "0     1\n",
            "1     1\n",
            "2     1\n",
            "3     1\n",
            "4     1\n",
            "5     0\n",
            "6     0\n",
            "7     0\n",
            "8     0\n",
            "9     0\n",
            "10    1\n",
            "11    0\n",
            "12    1\n",
            "13    0\n",
            "14    1\n",
            "15    0\n",
            "16    1\n",
            "17    0\n",
            "Name: labelnum, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "145d2b79",
        "outputId": "51658105-e633-44cb-8650-2281f5baca72"
      },
      "source": [
        "#splitting the dataset into train and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "xtrain,xtest,ytrain,ytest=train_test_split(X,y)\n",
        "print ('\\n The total number of Training Data :',ytrain.shape)\n",
        "print ('\\n The total number of Test Data :',ytest.shape)\n",
        "\n"
      ],
      "id": "145d2b79",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " The total number of Training Data : (13,)\n",
            "\n",
            " The total number of Test Data : (5,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c68f2f4",
        "outputId": "c3ae0e0a-b8c8-4384-8345-6863e209cae0"
      },
      "source": [
        "#output of count vectoriser is a sparse matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "xtrain_dtm = count_vect.fit_transform(xtrain)\n",
        "xtest_dtm=count_vect.transform(xtest)\n",
        "print('\\n The words or Tokens in the text documents \\n')\n",
        "print(count_vect.get_feature_names())\n",
        "df=pd.DataFrame(xtrain_dtm.toarray(),columns=count_vect.get_feature_names())\n"
      ],
      "id": "3c68f2f4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " The words or Tokens in the text documents \n",
            "\n",
            "['am', 'amazing', 'an', 'and', 'awesome', 'bad', 'best', 'boss', 'can', 'dance', 'deal', 'do', 'enemy', 'fun', 'good', 'have', 'he', 'horrible', 'house', 'is', 'like', 'locality', 'love', 'my', 'not', 'of', 'place', 'restaurant', 'sick', 'stay', 'stuff', 'sworn', 'that', 'this', 'tired', 'to', 'today', 'tomorrow', 'we', 'went', 'will', 'with', 'work']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e15a7afa"
      },
      "source": [
        "# Training Naive Bayes (NB) classifier on training data.\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB().fit(xtrain_dtm,ytrain)\n",
        "predicted = clf.predict(xtest_dtm)\n",
        "\n"
      ],
      "id": "e15a7afa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11035ddb",
        "outputId": "f2a0d61b-514b-4ca6-ce96-f20591deaff1"
      },
      "source": [
        "#printing accuracy, Confusion matrix, Precision and Recall\n",
        "from sklearn import metrics\n",
        "print('Accuracy metrics')\n",
        "print('Accuracy of the classifer is',metrics.accuracy_score(ytest,predicted))\n",
        "print('Confusion matrix')\n",
        "print(metrics.confusion_matrix(ytest,predicted))\n",
        "print('Recall and Precison ')\n",
        "print(metrics.recall_score(ytest,predicted))\n",
        "print(metrics.precision_score(ytest,predicted))"
      ],
      "id": "11035ddb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy metrics\n",
            "Accuracy of the classifer is 0.8\n",
            "Confusion matrix\n",
            "[[1 0]\n",
            " [1 3]]\n",
            "Recall and Precison \n",
            "0.75\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52dcf9a9"
      },
      "source": [
        "### 2.\tBuild an Artificial Neural Network by implementing the Backpropagation algorithm and test the same using appropriate data sets. K-NN and Weighted- KNN classifiers"
      ],
      "id": "52dcf9a9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9e0b569"
      },
      "source": [
        "#### Initializing variables value"
      ],
      "id": "c9e0b569"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9bb616c",
        "outputId": "26660c50-5d5c-4b71-9d74-6946cbadb9cd"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n",
        "\n",
        "print(\"small x\",x)\n",
        "\n",
        "#original output \n",
        "\n",
        "y = np.array(([92], [86], [89]), dtype=float)\n",
        "\n",
        "X = x/np.amax(x,axis=0) #maximum along the first axis \n",
        "\n",
        "print(\"Capital X\",X)"
      ],
      "id": "b9bb616c",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "small x [[2. 9.]\n",
            " [1. 5.]\n",
            " [3. 6.]]\n",
            "Capital X [[0.66666667 1.        ]\n",
            " [0.33333333 0.55555556]\n",
            " [1.         0.66666667]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85ffcd6e"
      },
      "source": [
        "#Defining Sigmoid Function for output \n",
        "\n",
        "def sigmoid (x):\n",
        "\n",
        "    return (1/(1 + np.exp(-x)))\n",
        "\n",
        "#Derivative of Sigmoid Function\n",
        "\n",
        "def derivatives_sigmoid(x):\n",
        "\n",
        "    return x * (1 - x)\n",
        "\n",
        "#Variables initialization\n",
        "\n",
        "epoch=7000 #Setting training iterations\n",
        "\n",
        "lr=0.1 #Setting learning rate\n",
        "\n",
        "inputlayer_neurons = 2 #number of input layer neurons \n",
        "\n",
        "hiddenlayer_neurons = 3 #number of hidden layers neurons\n",
        "\n",
        "output_neurons = 1 #number of neurons at output layer"
      ],
      "id": "85ffcd6e",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15d3314e"
      },
      "source": [
        "Note:\n",
        "\n",
        "1)In this code,we have defined  sigmoid function and its derivative function."
      ],
      "id": "15d3314e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8301fb06"
      },
      "source": [
        "2)As you know, we train the Neural network many times at a single point, for that we need the number of epochs."
      ],
      "id": "8301fb06"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50643b28"
      },
      "source": [
        "3)Below that we have defined the only  number of neurons in each layer."
      ],
      "id": "50643b28"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b571857"
      },
      "source": [
        "#Defining weight and biases for hidden and output layer \n",
        "\n",
        "wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))\n",
        "\n",
        "bh=np.random.uniform(size=(1,hiddenlayer_neurons))\n",
        "\n",
        "wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))\n",
        "\n",
        "bout=np.random.uniform(size=(1,output_neurons))"
      ],
      "id": "1b571857",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f170b193"
      },
      "source": [
        "Note: \n",
        "\n",
        "1.Here we have defined random weights and bias"
      ],
      "id": "f170b193"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2281ffeb"
      },
      "source": [
        "2.As we know, we should first defined the weights and Bias for the first (here we have only one hidden layer) hidden layer."
      ],
      "id": "2281ffeb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c26f156c"
      },
      "source": [
        "3.After that we have defined the weights and bias for the output layer."
      ],
      "id": "c26f156c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c55f1db2"
      },
      "source": [
        "4.Keep in mind when defining the weights size (how many neurons are in the previous layer, the number of neurons in the layer for that we have defined weights)."
      ],
      "id": "c55f1db2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3851e1d4"
      },
      "source": [
        "5.Size of bias (number of neurons in output layer,the number of neurons in the layer for that we have defined biases)."
      ],
      "id": "3851e1d4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c735a5a4"
      },
      "source": [
        "#Forward Propagation \n",
        "\n",
        "for i in range(epoch):\n",
        "\n",
        "    hinp1=np.dot(X,wh) \n",
        "\n",
        "    hinp=hinp1 + bh\n",
        "\n",
        "    hlayer_act = sigmoid(hinp)\n",
        "\n",
        "    outinp1=np.dot(hlayer_act,wout)\n",
        "\n",
        "    outinp= outinp1+ bout\n",
        "\n",
        "    output = sigmoid(outinp)"
      ],
      "id": "c735a5a4",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "282ac0df"
      },
      "source": [
        "Note:\n",
        "\n",
        "1.Here we are just calculating output of our model, first we have done this for hidden layer and after that for output layer , and finally get the output."
      ],
      "id": "282ac0df"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8afda585"
      },
      "source": [
        "2.np.dot is used for dot product of two matrix."
      ],
      "id": "8afda585"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e48270c",
        "outputId": "eb08a63e-0f8b-4fb9-bbfd-d386ee9de796"
      },
      "source": [
        "#Backpropagation Algorithm \n",
        "\n",
        "EO = y-output\n",
        "\n",
        "outgrad = derivatives_sigmoid(output)\n",
        "\n",
        "d_output = EO* outgrad\n",
        "\n",
        "EH = d_output.dot(wout.T)\n",
        "\n",
        "hiddengrad = derivatives_sigmoid(hlayer_act)\n",
        "\n",
        "#how much hidden layer wts contributed to error\n",
        "\n",
        "d_hiddenlayer = EH * hiddengrad\n",
        "\n",
        "wout += hlayer_act.T.dot(d_output) *lr\n",
        "\n",
        "# dotproduct of nextlayererror and currentlayerop\n",
        "\n",
        "bout += np.sum(d_output, axis=0,keepdims=True) *lr\n",
        "\n",
        "#Updating Weights\n",
        "\n",
        "wh += X.T.dot(d_hiddenlayer) *lr\n",
        "\n",
        "print(\"Actual Output: \\n\" + str(y))\n",
        "\n",
        "print(\"Predicted Output: \\n\" ,output)"
      ],
      "id": "8e48270c",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual Output: \n",
            "[[92.]\n",
            " [86.]\n",
            " [89.]]\n",
            "Predicted Output: \n",
            " [[0.71291985]\n",
            " [0.7074581 ]\n",
            " [0.71405303]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a661d0e"
      },
      "source": [
        "Note: \n",
        "\n",
        "1.In this code first we calculated error of hidden layer and after that calculated error of output layer."
      ],
      "id": "4a661d0e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cac3f70a"
      },
      "source": [
        "2.As we know from the formula we have to find out  how much hidden layer contribute in total error and also contribution of weight in total error."
      ],
      "id": "cac3f70a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12a96151"
      },
      "source": [
        "3.After that we have updated our weights and biases, until we get minimum error."
      ],
      "id": "12a96151"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e149b47f"
      },
      "source": [
        "4.X.T is used to make transpose matrix."
      ],
      "id": "e149b47f"
    }
  ]
}